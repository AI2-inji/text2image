{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "model.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "6RZTSOVMJ95z",
        "73SvNFOoKC1v",
        "2rYQkLELKLRX",
        "69-6glEUKVRI",
        "erhzOTxlMu56"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "81e7b78038554ee4a95d2004574bd1ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_31e4b99d3bd74838b28535c72eed0055",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_944db3d700014dd5beec226b770ef1a3",
              "IPY_MODEL_55928a0050cd4e3b8bebf1001e51471d"
            ]
          }
        },
        "31e4b99d3bd74838b28535c72eed0055": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "944db3d700014dd5beec226b770ef1a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_e8519f8a369d4501b6cb0139c54483fb",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 279173,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 279173,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_943e9ebe09044480a92bbff9f01812cf"
          }
        },
        "55928a0050cd4e3b8bebf1001e51471d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_b895f270bafc4f65877b6f262a0da1c1",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 279k/279k [00:01&lt;00:00, 149kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_eb3e1abbbb084600877ef37538667a71"
          }
        },
        "e8519f8a369d4501b6cb0139c54483fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "943e9ebe09044480a92bbff9f01812cf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b895f270bafc4f65877b6f262a0da1c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "eb3e1abbbb084600877ef37538667a71": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8f29af43bee14da4bc69bbdcead97874": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_98fca4a6e3274b3ea90eda671c4f89c8",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_9492dfc06fa748b782dbc0afdafcafdf",
              "IPY_MODEL_6db970039a014f448a637ec8a5052399"
            ]
          }
        },
        "98fca4a6e3274b3ea90eda671c4f89c8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9492dfc06fa748b782dbc0afdafcafdf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_b67f1feee77840b097aa323e337f5864",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 51,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 51,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3e903eb7e02a44e5b0a641570295cc07"
          }
        },
        "6db970039a014f448a637ec8a5052399": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_d93709d4c81b4f048b16a3b3d728bd45",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 51.0/51.0 [00:00&lt;00:00, 104B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_11023ad01cf644c88711f88a259e1240"
          }
        },
        "b67f1feee77840b097aa323e337f5864": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3e903eb7e02a44e5b0a641570295cc07": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d93709d4c81b4f048b16a3b3d728bd45": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "11023ad01cf644c88711f88a259e1240": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6RZTSOVMJ95z",
        "colab_type": "text"
      },
      "source": [
        "# Import"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N8v667z1jOqR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m7uk57j9Ne7e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install transformers\n",
        "!pip install --upgrade pip\n",
        "!pip install transformers\n",
        "!pip install torch torchvision\n",
        "!pip install --upgrade tensorflow"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wsN8udj7Nmva",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "3b78e061-aea6-42dc-86e1-faf75cf20c3f"
      },
      "source": [
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import time\n",
        "\n",
        "from PIL import Image\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import multi_gpu_model\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "from transformers import TFElectraModel, ElectraTokenizer\n",
        "\n",
        "#drive.mount('/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /gdrive; to attempt to forcibly remount, call drive.mount(\"/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "73SvNFOoKC1v",
        "colab_type": "text"
      },
      "source": [
        "# parameter set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FCdN7uzMxETA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "referenced_widgets": [
            "81e7b78038554ee4a95d2004574bd1ab",
            "31e4b99d3bd74838b28535c72eed0055",
            "944db3d700014dd5beec226b770ef1a3",
            "55928a0050cd4e3b8bebf1001e51471d",
            "e8519f8a369d4501b6cb0139c54483fb",
            "943e9ebe09044480a92bbff9f01812cf",
            "b895f270bafc4f65877b6f262a0da1c1",
            "eb3e1abbbb084600877ef37538667a71",
            "8f29af43bee14da4bc69bbdcead97874",
            "98fca4a6e3274b3ea90eda671c4f89c8",
            "9492dfc06fa748b782dbc0afdafcafdf",
            "6db970039a014f448a637ec8a5052399",
            "b67f1feee77840b097aa323e337f5864",
            "3e903eb7e02a44e5b0a641570295cc07",
            "d93709d4c81b4f048b16a3b3d728bd45",
            "11023ad01cf644c88711f88a259e1240"
          ]
        },
        "outputId": "cd4a6b43-531a-472d-c9ec-5199503054e6"
      },
      "source": [
        "#base_path = '/gdrive/My Drive/project/text_to_image'\n",
        "base_path = '/home/ec2-user/SageMaker'\n",
        "\n",
        "tokenizer = ElectraTokenizer.from_pretrained(\"monologg/koelectra-small-discriminator\")\n",
        "\n",
        "sequence_len = 80  # 바꿔야함\n",
        "embedding_size = 256\n",
        "\n",
        "stage1_generator_lr = 0.0002\n",
        "stage1_discriminator_lr = 0.0002\n",
        "stage1_epochs = 1000\n",
        "stage1_batch_size = 32\n",
        "\n",
        "stage2_generator_lr = 0.0002\n",
        "stage2_discriminator_lr = 0.0002\n",
        "stage2_epochs = 500\n",
        "stage2_batch_size = 4"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "81e7b78038554ee4a95d2004574bd1ab",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=279173.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8f29af43bee14da4bc69bbdcead97874",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=51.0, style=ProgressStyle(description_w…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2rYQkLELKLRX",
        "colab_type": "text"
      },
      "source": [
        "# model build function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ftMp6EzlOJl7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def embedding_reshape():\n",
        "    # 1차원인 임베딩 벡터를 파라미터 조절해서 차원 맞추기\n",
        "    # 얘도 가중치 공유해야해서 따로 만듦\n",
        "    x = Sequential(\n",
        "        layers=[\n",
        "                layers.Dense(128),\n",
        "                layers.Reshape((1, 1, 128)),\n",
        "                layers.Lambda(lambda x: tf.tile(x, (1, 4, 4, 1)))\n",
        "        ]\n",
        "    )\n",
        "    return x\n",
        "\n",
        "\n",
        "def generate_c(x):\n",
        "    # dot, add 연산을 수행하는 람다 레이어에 들어갈 함수\n",
        "    mean = x[:, :128]\n",
        "    log_sigma = x[:, 128:]\n",
        "    stddev = tf.exp(log_sigma)\n",
        "    epsilon = tf.random.normal(shape=tf.constant((mean.shape[1],), dtype=tf.int32))\n",
        "    c = stddev * epsilon + mean\n",
        "    return c\n",
        "\n",
        "\n",
        "def get_up_sampling(filters):\n",
        "    # 업샘플링 코드 반복 최소화를 위한 함수\n",
        "    x = Sequential(\n",
        "        layers=[\n",
        "                layers.UpSampling2D(size=(2, 2)),\n",
        "                layers.Conv2D(filters, kernel_size=3, padding=\"same\", strides=1, use_bias=False),\n",
        "                layers.BatchNormalization(),\n",
        "                layers.ReLU()\n",
        "        ]\n",
        "    )\n",
        "    return x\n",
        "\n",
        "\n",
        "def get_down_sampling(filters):\n",
        "    # 다운샘플링 코드 반복 최소화를 위한 함수\n",
        "    x = Sequential(\n",
        "        layers=[\n",
        "                layers.Conv2D(filters, (4, 4), padding='same', strides=2, use_bias=False),\n",
        "                layers.BatchNormalization(),\n",
        "                layers.LeakyReLU(alpha=0.2)\n",
        "        ]\n",
        "    )\n",
        "    return x\n",
        "\n",
        "\n",
        "def build_stage1_generator():\n",
        "    # 텍스트\n",
        "    input_text = layers.Input(shape=(sequence_len,), dtype=tf.int32)\n",
        "    embeded = Sequential(\n",
        "        layers=[\n",
        "                TFElectraModel.from_pretrained(\"monologg/koelectra-small-discriminator\", from_pt=True).get_input_embeddings(),\n",
        "                layers.Dense(4),\n",
        "                layers.Flatten(),\n",
        "                layers.Dense(embedding_size),\n",
        "                layers.LeakyReLU(alpha=0.2)\n",
        "        ],\n",
        "        name='embedding'\n",
        "    )(input_text)\n",
        "    # embeded = layers.Dense(embedding_size)(input_text)\n",
        "    # embeded = layers.LeakyReLU(alpha=0.2)(embeded)\n",
        "\n",
        "    c = layers.Lambda(generate_c)(embeded)\n",
        "\n",
        "    # 노이즈\n",
        "    input_noise = layers.Input(shape=(100,))\n",
        "\n",
        "    # 처리된 텍스트와 노이즈를 함쳐줌\n",
        "    gen_input = layers.Concatenate(axis=1)([c, input_noise])\n",
        "    \n",
        "    # 모양 맞춰서 reshape\n",
        "    x = layers.Dense(128 * 8 * 4 * 4, activation='relu', use_bias=False)(gen_input)\n",
        "    x = layers.Reshape((4, 4, 128 * 8), input_shape=(128 * 8 * 4 * 4,))(x)\n",
        "\n",
        "    # (batch_size, 64, 64, 64) 까지 업샘플링\n",
        "    x = get_up_sampling(512)(x)\n",
        "    x = get_up_sampling(256)(x)\n",
        "    x = get_up_sampling(128)(x)\n",
        "    x = get_up_sampling(64)(x)\n",
        "\n",
        "    # 이미지에 맞게 (batch_size, 64, 64, 3) 으로 채널 수 맞춰주기\n",
        "    x = layers.Conv2D(3, kernel_size=3, padding=\"same\", strides=1, activation='tanh', use_bias=False)(x)\n",
        "\n",
        "    stage1_gen = Model(inputs=[input_text, input_noise], outputs=[x, embeded], name='stage_1_generator')\n",
        "    return stage1_gen\n",
        "\n",
        "\n",
        "def build_stage1_discriminator(embedding_reshape_layer):\n",
        "    # 만들어진 이미지\n",
        "    generated_image = layers.Input(shape=(64, 64, 3))\n",
        "\n",
        "    x = layers.Conv2D(64, kernel_size=4, padding='same', strides=2, use_bias=False)(generated_image)\n",
        "    x = layers.LeakyReLU(alpha=0.2)(x)\n",
        "\n",
        "    # (batch_size, 4, 4, 512) 까지 다운샘플링\n",
        "    x = get_down_sampling(128)(x)\n",
        "    x = get_down_sampling(256)(x)\n",
        "    x = get_down_sampling(512)(x)\n",
        "\n",
        "    # 임베딩된 텍스트. generator에서 출력함.\n",
        "    input_text = layers.Input(shape=(embedding_size,))\n",
        "    input_text_repeated = embedding_reshape_layer(input_text)\n",
        "    \n",
        "\n",
        "    # 붙여주고\n",
        "    merged_input = layers.concatenate([x, input_text_repeated])\n",
        "\n",
        "\n",
        "    # sigmoid 최종 처리\n",
        "    x2 = layers.Conv2D(64 * 8, kernel_size=1, padding=\"same\", strides=1)(merged_input)\n",
        "    x2 = layers.BatchNormalization()(x2)\n",
        "    x2 = layers.LeakyReLU(alpha=0.2)(x2)\n",
        "    x2 = layers.Flatten()(x2)\n",
        "    x2 = layers.Dense(1, activation='sigmoid')(x2)\n",
        "\n",
        "    stage1_dis = Model(inputs=[generated_image, input_text], outputs=[x2], name='stage_1_discriminator')\n",
        "    return stage1_dis"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R55FVIpBqsAH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_residual_block():\n",
        "    x = layers.Input((16, 16, 128 * 4))\n",
        "    residual = layers.Conv2D(128 * 4, kernel_size=1, padding=\"same\", strides=1, use_bias=False)(x)\n",
        "    residual = layers.BatchNormalization()(x)\n",
        "    residual = layers.Activation('relu')(residual)\n",
        "    merged = layers.add([x, residual])\n",
        "\n",
        "    return Model(x, merged)\n",
        "\n",
        "\n",
        "def build_stage2_generator():\n",
        "    # stage1 에서 만든 이미지\n",
        "    generated_image = layers.Input(shape=(64, 64, 3))\n",
        "    x = get_down_sampling(256)(generated_image)\n",
        "    x = get_down_sampling(512)(x)\n",
        "\n",
        "    # 텍스트\n",
        "    input_text = layers.Input(shape=(embedding_size,))\n",
        "    c = layers.Lambda(generate_c)(input_text)\n",
        "    embedding = layers.Dense(16 * 16 * 128 * 8)(input_text)\n",
        "    embedding = layers.LeakyReLU(alpha=0.2)(embedding)\n",
        "    embedding = layers.Reshape((16, 16, 128 * 8))(embedding)\n",
        "\n",
        "    # 붙이고 차원 맞추기\n",
        "    merged_input = layers.concatenate([x, embedding])\n",
        "    x = layers.Conv2D(128 * 4, kernel_size=3, padding=\"same\", strides=1)(merged_input)\n",
        "\n",
        "    # 잔차 연결. 조금 줄여도 될 듯?\n",
        "    x = get_residual_block()(x)\n",
        "    x = get_residual_block()(x)\n",
        "    x = get_residual_block()(x)\n",
        "    x = get_residual_block()(x)\n",
        "\n",
        "    # 512까지 업샘플링\n",
        "    x = get_up_sampling(512)(x)\n",
        "    x = get_up_sampling(256)(x)\n",
        "    x = get_up_sampling(128)(x)\n",
        "    x = get_up_sampling(64)(x)\n",
        "    x = get_up_sampling(32)(x)\n",
        "\n",
        "    x = layers.Conv2D(3, kernel_size=3, padding=\"same\", strides=1, activation='tanh', use_bias=False)(x)\n",
        "\n",
        "    return Model(inputs=[generated_image, input_text], outputs=x, name='stage_2_generator')\n",
        "\n",
        "\n",
        "def build_stage2_discriminator(embedding_reshape_layer):\n",
        "    # 만들어진 이미지\n",
        "    generated_image = layers.Input(shape=(512, 512, 3))\n",
        "\n",
        "    x = layers.Conv2D(512, kernel_size=3, padding=\"same\", strides=2)(generated_image)\n",
        "    x = layers.LeakyReLU(alpha=0.2)(x)\n",
        "\n",
        "    # (batch_size, 4, 4, 512) 까지 다운샘플링\n",
        "    x = get_down_sampling(16)(x)\n",
        "    x = get_down_sampling(32)(x)\n",
        "    x = get_down_sampling(64)(x)\n",
        "    x = get_down_sampling(128)(x)\n",
        "    x = get_down_sampling(256)(x)\n",
        "    x = get_down_sampling(512)(x)\n",
        "\n",
        "    # 임베딩된 텍스트. generator에서 출력함.\n",
        "    input_text = layers.Input(shape=(embedding_size,))\n",
        "    input_text_repeated = embedding_reshape_layer(input_text)\n",
        "    \n",
        "\n",
        "    # 붙여주고\n",
        "    merged_input = layers.concatenate([x, input_text_repeated])\n",
        "\n",
        "\n",
        "    # sigmoid 최종 처리\n",
        "    x2 = layers.Conv2D(512 * 8, kernel_size=1,\n",
        "                padding=\"same\", strides=1)(merged_input)\n",
        "    x2 = layers.BatchNormalization()(x2)\n",
        "    x2 = layers.LeakyReLU(alpha=0.2)(x2)\n",
        "    x2 = layers.Flatten()(x2)\n",
        "    x2 = layers.Dense(1, activation='sigmoid')(x2)\n",
        "\n",
        "    return Model(inputs=[generated_image, input_text], outputs=[x2], name='stage_2_discriminator')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "69-6glEUKVRI",
        "colab_type": "text"
      },
      "source": [
        "# build_adversarial_model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jVvqLWQj6XLx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_stage_1_adversarial_model(gen_model, dis_model):\n",
        "    input_layer = layers.Input(shape=(sequence_len,))\n",
        "    input_layer2 = layers.Input(shape=(100,))\n",
        "\n",
        "    x, mean_logsigma = gen_model([input_layer, input_layer2])\n",
        "\n",
        "    dis_model.trainable = False\n",
        "    valid = dis_model([x, mean_logsigma])\n",
        "\n",
        "    model = Model(inputs=[input_layer, input_layer2], outputs=[valid, mean_logsigma])\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5MjpWz5EK64D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_stage_2_adversarial_model(gen_model_1, gen_model_2, dis_model):\n",
        "    input_layer = layers.Input(shape=(sequence_len,))\n",
        "    input_layer2 = layers.Input(shape=(100,))\n",
        "\n",
        "    gen_model_1.trainable = False\n",
        "    x, mean_logsigma = gen_model_1([input_layer, input_layer2])\n",
        "    x = gen_model_2([x, mean_logsigma])\n",
        "\n",
        "    dis_model.trainable = False\n",
        "    valid = dis_model([x, mean_logsigma])\n",
        "\n",
        "    model = Model(inputs=[input_layer, input_layer2], outputs=valid)\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pkNiUoPOrofZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_full_generator(gen_model_1, gen_model_2):\n",
        "    input_layer = layers.Input(shape=(sequence_len,))\n",
        "    input_layer2 = layers.Input(shape=(100,))\n",
        "\n",
        "    gen_model_1.trainable = False\n",
        "    gen_model_2.trainable = False\n",
        "\n",
        "    x, mean_logsigma = gen_model_1([input_layer, input_layer2])\n",
        "    x = gen_model_2([x, mean_logsigma])\n",
        "\n",
        "    model = Model(inputs=[input_layer, input_layer2], outputs=[x, mean_logsigma])\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "erhzOTxlMu56",
        "colab_type": "text"
      },
      "source": [
        "# model build"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VkJMZ1hael8e",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "outputId": "ad4b659a-9480-479c-81af-64d40920558b"
      },
      "source": [
        "em_reshape = embedding_reshape()\n",
        "\n",
        "stage_1_generator = build_stage1_generator()\n",
        "stage_1_discriminator = build_stage1_discriminator(em_reshape)\n",
        "stage_1_adversarial_model = build_stage_1_adversarial_model(stage_1_generator, stage_1_discriminator)\n",
        "\n",
        "embedding_layer = stage_1_generator.layers[1]\n",
        "\n",
        "stage_2_generator = build_stage2_generator()\n",
        "stage_2_discriminator = build_stage2_discriminator(em_reshape)\n",
        "stage_2_adversarial_model = build_stage_2_adversarial_model(stage_1_generator, stage_2_generator, stage_2_discriminator)\n",
        "\n",
        "full_generator = build_full_generator(stage_1_generator, stage_2_generator)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "All PyTorch model weights were used when initializing TFElectraModel.\n",
            "\n",
            "Some weights or buffers of the PyTorch model TFElectraModel were not initialized from the TF 2.0 model and are newly initialized: ['discriminator_predictions.dense_prediction.bias', 'discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense.bias', 'discriminator_predictions.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-zYyHVM-kC7g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stage_1_generator = multi_gpu_model(stage_1_generator, gpus=2)\n",
        "stage_1_discriminator = multi_gpu_model(stage_1_discriminator, gpus=2)\n",
        "stage_1_adversarial_model = multi_gpu_model(stage_1_adversarial_model, gpus=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ox1fBw-GMzsO",
        "colab_type": "text"
      },
      "source": [
        "# define loss and util function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_NiLa1bFiHQM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def KL_loss(y_true, y_pred):\n",
        "    mean = y_pred[:, :128]\n",
        "    logsigma = y_pred[:, :128]\n",
        "    loss = -logsigma + .5 * (-1 + tf.exp(2. * logsigma) + tf.square(mean))\n",
        "    loss = tf.math.reduce_mean(loss)\n",
        "    return loss\n",
        "\n",
        "def save_rgb_img(img, path):\n",
        "    img = (img * 127.5 + 127.5).astype(int)\n",
        "    fig = plt.figure()\n",
        "    ax = fig.add_subplot(1, 1, 1)\n",
        "    ax.imshow(img)\n",
        "    ax.axis(\"off\")\n",
        "    ax.set_title(\"Image\")\n",
        "\n",
        "    plt.savefig(path)\n",
        "    plt.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j1bN0qiZnsfg",
        "colab_type": "text"
      },
      "source": [
        "# dataset define"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cDhG7Y1LTi--",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_excel(os.path.join(base_path, 'text_data.xlsx')).dropna()\n",
        "text = df['text'].to_list()\n",
        "text_negative = text[1:] + [text[1]]\n",
        "\n",
        "text = sum([[tokenizer.encode(t)] * 20 for t in text], [])\n",
        "text_negative = sum([[tokenizer.encode(t)] * 20 for t in text_negative], [])\n",
        "\n",
        "filenames = sorted(os.listdir(os.path.join(base_path, 'transform_img')))\n",
        "filenames = [os.path.join(base_path + '/transform_img', f) for f in filenames]\n",
        "\n",
        "assert len(text) == len(filenames), \"shape가 맞지 않음\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hVlzlRXuZjLp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text = pad_sequences(text, maxlen=sequence_len, dtype=np.int32, truncating=\"post\", padding=\"post\")\n",
        "text_negative = pad_sequences(text_negative, maxlen=sequence_len, dtype=np.int32, truncating=\"post\", padding=\"post\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D3d2N5OACdkW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "filenames = np.array(filenames)\n",
        "\n",
        "s = np.arange(text.shape[0])\n",
        "np.random.shuffle(s)\n",
        "\n",
        "text = text[s]\n",
        "text_negative = text_negative[s]\n",
        "filenames = list(filenames[s])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9__57DC6OusR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# real_labels = np.ones((stage1_batch_size, 1), dtype=float) * 0.9\n",
        "# fake_labels = np.zeros((stage1_batch_size, 1), dtype=float) * 0.1\n",
        "real_labels = np.ones((stage1_batch_size, 1), dtype=float)\n",
        "fake_labels = np.zeros((stage1_batch_size, 1), dtype=float)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DYejEh1yNAXA",
        "colab_type": "text"
      },
      "source": [
        "# stage 1 train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1kt5fflYNPnB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dis_optimizer = Adam(lr=stage1_discriminator_lr, beta_1=0.5, beta_2=0.999)\n",
        "gen_optimizer = Adam(lr=stage1_generator_lr, beta_1=0.5, beta_2=0.999)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ab4mNnbUNx6N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stage_1_generator.compile(loss=\"mse\", optimizer=gen_optimizer)\n",
        "stage_1_discriminator.compile(loss='binary_crossentropy', optimizer=dis_optimizer)\n",
        "stage_1_adversarial_model.compile(loss=['binary_crossentropy', KL_loss], loss_weights=[1, 2.0], optimizer=gen_optimizer, metrics=None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ug7MiAH7xyTW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "generator_losses = []\n",
        "discriminator_losses = []\n",
        "\n",
        "for epoch in range(stage1_epochs):\n",
        "    number_of_batches = int(text.shape[0] / stage1_batch_size)\n",
        "\n",
        "    print(\"========================================\")\n",
        "    print(f\"Epoch is: {epoch}, Number of batches: {number_of_batches}\")\n",
        "\n",
        "    gen_losses = []\n",
        "    dis_losses = []\n",
        "\n",
        "\n",
        "    for index in tqdm(range(number_of_batches)):\n",
        "\n",
        "        # 판별자 학습\n",
        "        z_noise = np.random.normal(size=(stage1_batch_size, 100))\n",
        "        # 이미지\n",
        "        image_batch = []\n",
        "        for fname in filenames[index * stage1_batch_size : (index + 1) * stage1_batch_size]:\n",
        "            img = Image.open(fname).resize((64, 64))\n",
        "            # img\n",
        "            image_batch.append(np.array(img))\n",
        "        image_batch = np.array(image_batch)\n",
        "        image_batch = (image_batch - 127.5) / 127.5\n",
        "\n",
        "        # 텍스트\n",
        "        text_batch = text[index * stage1_batch_size : (index + 1) * stage1_batch_size]\n",
        "        text_negative_batch = text_negative[index * stage1_batch_size : (index + 1) * stage1_batch_size]\n",
        "\n",
        "        # 생성된 이미지\n",
        "        fake_image_batch, embedding = stage_1_generator.predict([text_batch, z_noise])\n",
        "\n",
        "        # 가짜 임베딩\n",
        "        dismatched_embedding = embedding_layer.predict(text_negative_batch)\n",
        "\n",
        "        # 실제 이미지나 가짜 이미지나 사용한 텍스트는 같음. 그래서 임베딩은 공유함\n",
        "        # 매치되지 않는 이미지 역시 이미지는 공유하나 사용한 텍스트가 다름. 그래서 이미지는 공유\n",
        "        dis_loss_real = stage_1_discriminator.train_on_batch([image_batch, embedding], real_labels)\n",
        "        dis_loss_fake = stage_1_discriminator.train_on_batch([fake_image_batch, embedding], fake_labels)\n",
        "        dis_loss_wrong = stage_1_discriminator.train_on_batch([image_batch, dismatched_embedding], fake_labels)\n",
        "\n",
        "        d_loss = 0.5 * np.add(dis_loss_real, 0.5 * np.add(dis_loss_wrong, dis_loss_fake))\n",
        "\n",
        "        # 제너레이터 학습\n",
        "        \n",
        "        g_loss = np.mean([\n",
        "            stage_1_adversarial_model.train_on_batch([text_batch, z_noise],[tf.ones((stage1_batch_size, 1)), tf.ones((stage1_batch_size, 256))])\n",
        "            for _ in range(3)\n",
        "        ])\n",
        "\n",
        "        dis_losses.append(d_loss)\n",
        "        gen_losses.append(g_loss)\n",
        "        \n",
        "    generator_losses.append(np.mean(gen_losses))\n",
        "    discriminator_losses.append(np.mean(dis_losses))\n",
        "        \n",
        "    if generator_losses[-1] == np.min(generator_losses):\n",
        "        stage_1_generator.save_weights(os.path.join(base_path + '/models', 'stage_1_generator.h5'))\n",
        "    if discriminator_losses[-1] == np.min(discriminator_losses):\n",
        "        stage_1_discriminator.save_weights(os.path.join(base_path + '/models', 'stage_1_discriminator.h5'))\n",
        "\n",
        "   \n",
        "    # 2에포크마다 제너레이터가 생성한 이미지를 저장\n",
        "    if epoch % 2 == 0:\n",
        "        n = 5\n",
        "        fake_images, _ = stage_1_generator.predict([text[:n], np.random.normal(size=(n, 100))])\n",
        "\n",
        "        for i, img in enumerate(fake_images[:10]):\n",
        "            save_rgb_img(img, os.path.join(base_path + '/generated_image64', f\"stage1_generator-epoch{epoch: 4d}_{i}.png\"))\n",
        "\n",
        "    print(f\"generator_loss: {np.mean(gen_losses): .4f}\")\n",
        "    print(f\"discriminator_loss: {np.mean(dis_losses): .4f}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AKKJU-k-q6yZ",
        "colab_type": "text"
      },
      "source": [
        "# stage 2 train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "UcH3x9mbq_CH",
        "colab": {}
      },
      "source": [
        "dis_optimizer = Adam(lr=stage1_discriminator_lr, beta_1=0.5, beta_2=0.999)\n",
        "gen_optimizer = Adam(lr=stage1_generator_lr, beta_1=0.5, beta_2=0.999)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hW3ImVzMq_CP",
        "colab": {}
      },
      "source": [
        "stage_2_generator.compile(loss=\"mse\", optimizer=gen_optimizer)\n",
        "stage_2_discriminator.compile(loss='binary_crossentropy', optimizer=dis_optimizer)\n",
        "stage_2_adversarial_model.compile(loss='binary_crossentropy', optimizer=gen_optimizer, metrics=None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9NjRKDOTq42G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "generator_losses = []\n",
        "discriminator_losses = []\n",
        "\n",
        "for epoch in range(stage1_epochs):\n",
        "    number_of_batches = int(text.shape[0] / stage1_batch_size)\n",
        "\n",
        "    print(\"========================================\")\n",
        "    print(f\"Epoch is: {epoch}, Number of batches: {number_of_batches}\")\n",
        "\n",
        "    gen_losses = []\n",
        "    dis_losses = []\n",
        "\n",
        "\n",
        "    for index in tqdm(range(number_of_batches)):\n",
        "        \n",
        "        # 판별자 학습\n",
        "        z_noise = np.random.normal(size=(stage1_batch_size, 100))\n",
        "        # 이미지\n",
        "        image_batch = []\n",
        "        for fname in filenames[index * stage1_batch_size : (index + 1) * stage1_batch_size]:\n",
        "            img = Image.open(fname).resize((512, 512))\n",
        "            image_batch.append(np.asarray(img))\n",
        "        image_batch = np.array(image_batch)\n",
        "        image_batch = (image_batch - 127.5) / 127.5\n",
        "\n",
        "        # 텍스트\n",
        "        text_batch = text[index * stage1_batch_size : (index + 1) * stage1_batch_size]\n",
        "        text_negative_batch = text_negative[index * stage1_batch_size : (index + 1) * stage1_batch_size]\n",
        "\n",
        "        # 생성된 이미지\n",
        "        fake_image_batch, embedding = full_generator.predict([text_batch, z_noise])\n",
        "\n",
        "        # 가짜 임베딩\n",
        "        dismatched_embedding = embedding_layer.predict(text_negative_batch)\n",
        "\n",
        "        # 실제 이미지나 가짜 이미지나 사용한 텍스트는 같음. 그래서 임베딩은 공유함\n",
        "        # 매치되지 않는 이미지 역시 이미지는 공유하나 사용한 텍스트가 다름. 그래서 이미지는 공유\n",
        "        dis_loss_real = stage_2_discriminator.train_on_batch([image_batch, embedding], real_labels)\n",
        "        dis_loss_fake = stage_2_discriminator.train_on_batch([fake_image_batch, embedding], fake_labels)\n",
        "        dis_loss_wrong = stage_2_discriminator.train_on_batch([image_batch, dismatched_embedding], fake_labels)\n",
        "\n",
        "        d_loss = 0.5 * np.add(dis_loss_real, 0.5 * np.add(dis_loss_wrong, dis_loss_fake))\n",
        "\n",
        "        # 제너레이터 학습\n",
        "        g_loss = np.mean([\n",
        "            stage_2_adversarial_model.train_on_batch([text_batch, z_noise],[tf.ones((stage1_batch_size, 1)) * 0.9, tf.ones((stage1_batch_size, 256)) * 0.9])\n",
        "            for _ in range(3)\n",
        "        ])\n",
        "\n",
        "        dis_losses.append(d_loss)\n",
        "        gen_losses.append(g_loss)\n",
        "\n",
        "    generator_losses.append(np.mean(gen_losses))\n",
        "    discriminator_losses.append(np.mean(dis_losses))\n",
        "        \n",
        "    if generator_losses[-1] == np.min(generator_losses):\n",
        "        stage_2_generator.save(os.path.join(base_path + '/models', 'stage_2_generator.h5'))\n",
        "    if discriminator_losses[-1] == np.min(discriminator_losses):\n",
        "        stage_2_discriminator.save(os.path.join(base_path + '/models', 'stage_2_discriminator.h5'))\n",
        "\n",
        "   \n",
        "    # 2에포크마다 제너레이터가 생성한 이미지를 저장\n",
        "    if epoch % 2 == 0:\n",
        "        n = 1\n",
        "        fake_images, _ = full_generator.predict([text[:1], np.random.normal(size=(1, 100))])\n",
        "\n",
        "        for i, img in enumerate(fake_images[:10]):\n",
        "            save_rgb_img(img, os.path.join(base_path + '/generated_image512', f\"stage2_generator-epoch{epoch: 4d}_{i}.png\"))\n",
        "\n",
        "    print(f\"generator_loss: {np.mean(gen_losses): .4f}\")\n",
        "    print(f\"discriminator_loss: {np.mean(dis_losses): .4f}\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
